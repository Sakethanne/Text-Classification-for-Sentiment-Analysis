{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sakethanne/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sakethanne/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np   # For numerical operations\n",
    "import re            # Regular expressions for text processing\n",
    "from bs4 import BeautifulSoup  # For HTML parsing\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into training and testing sets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import nltk          # Natural Language Toolkit for text processing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')  # Download WordNet data\n",
    "nltk.download('stopwords')   # Download StopWords data\n",
    "\n",
    "import warnings      # To handle warnings\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore warnings for the remainder of the code\n",
    "warnings.filterwarnings(\"default\")  # Set warnings back to default behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install bs4 # in case you don't have it installed\n",
    "# ! pip install contractions # in case contractions are not already installed\n",
    "\n",
    "# # Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/d1tzxzhj3fzbmswz4z7m_40w0000gn/T/ipykernel_12645/1150709939.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  full_data = pd.read_csv(\"./amazon_reviews_us_Office_Products_v1_00.tsv\", delimiter='\\t', encoding='utf-8', error_bad_lines=False)\n",
      "Skipping line 20773: expected 15 fields, saw 22\n",
      "Skipping line 39834: expected 15 fields, saw 22\n",
      "Skipping line 52957: expected 15 fields, saw 22\n",
      "Skipping line 54540: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 80276: expected 15 fields, saw 22\n",
      "Skipping line 96168: expected 15 fields, saw 22\n",
      "Skipping line 96866: expected 15 fields, saw 22\n",
      "Skipping line 98175: expected 15 fields, saw 22\n",
      "Skipping line 112539: expected 15 fields, saw 22\n",
      "Skipping line 119377: expected 15 fields, saw 22\n",
      "Skipping line 120065: expected 15 fields, saw 22\n",
      "Skipping line 124703: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 134024: expected 15 fields, saw 22\n",
      "Skipping line 153938: expected 15 fields, saw 22\n",
      "Skipping line 156225: expected 15 fields, saw 22\n",
      "Skipping line 168603: expected 15 fields, saw 22\n",
      "Skipping line 187002: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 200397: expected 15 fields, saw 22\n",
      "Skipping line 203809: expected 15 fields, saw 22\n",
      "Skipping line 207680: expected 15 fields, saw 22\n",
      "Skipping line 223421: expected 15 fields, saw 22\n",
      "Skipping line 244032: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 270329: expected 15 fields, saw 22\n",
      "Skipping line 276484: expected 15 fields, saw 22\n",
      "Skipping line 304755: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 379449: expected 15 fields, saw 22\n",
      "Skipping line 386191: expected 15 fields, saw 22\n",
      "Skipping line 391811: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 414348: expected 15 fields, saw 22\n",
      "Skipping line 414773: expected 15 fields, saw 22\n",
      "Skipping line 417572: expected 15 fields, saw 22\n",
      "Skipping line 419496: expected 15 fields, saw 22\n",
      "Skipping line 430528: expected 15 fields, saw 22\n",
      "Skipping line 442230: expected 15 fields, saw 22\n",
      "Skipping line 450931: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 465377: expected 15 fields, saw 22\n",
      "Skipping line 467685: expected 15 fields, saw 22\n",
      "Skipping line 485055: expected 15 fields, saw 22\n",
      "Skipping line 487220: expected 15 fields, saw 22\n",
      "Skipping line 496076: expected 15 fields, saw 22\n",
      "Skipping line 512269: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 529505: expected 15 fields, saw 22\n",
      "Skipping line 531286: expected 15 fields, saw 22\n",
      "Skipping line 535424: expected 15 fields, saw 22\n",
      "Skipping line 569898: expected 15 fields, saw 22\n",
      "Skipping line 586293: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 593880: expected 15 fields, saw 22\n",
      "Skipping line 599274: expected 15 fields, saw 22\n",
      "Skipping line 607961: expected 15 fields, saw 22\n",
      "Skipping line 612413: expected 15 fields, saw 22\n",
      "Skipping line 615913: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 677580: expected 15 fields, saw 22\n",
      "Skipping line 687191: expected 15 fields, saw 22\n",
      "Skipping line 710819: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 728692: expected 15 fields, saw 22\n",
      "Skipping line 730216: expected 15 fields, saw 22\n",
      "Skipping line 758397: expected 15 fields, saw 22\n",
      "Skipping line 760061: expected 15 fields, saw 22\n",
      "Skipping line 768935: expected 15 fields, saw 22\n",
      "Skipping line 769483: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 822725: expected 15 fields, saw 22\n",
      "Skipping line 823621: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 857041: expected 15 fields, saw 22\n",
      "Skipping line 857320: expected 15 fields, saw 22\n",
      "Skipping line 858565: expected 15 fields, saw 22\n",
      "Skipping line 860629: expected 15 fields, saw 22\n",
      "Skipping line 864033: expected 15 fields, saw 22\n",
      "Skipping line 868673: expected 15 fields, saw 22\n",
      "Skipping line 869189: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 938605: expected 15 fields, saw 22\n",
      "Skipping line 940100: expected 15 fields, saw 22\n",
      "Skipping line 975137: expected 15 fields, saw 22\n",
      "Skipping line 976314: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 985597: expected 15 fields, saw 22\n",
      "Skipping line 990873: expected 15 fields, saw 22\n",
      "Skipping line 991806: expected 15 fields, saw 22\n",
      "Skipping line 1019808: expected 15 fields, saw 22\n",
      "Skipping line 1021526: expected 15 fields, saw 22\n",
      "Skipping line 1023905: expected 15 fields, saw 22\n",
      "Skipping line 1044207: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1084683: expected 15 fields, saw 22\n",
      "Skipping line 1093288: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1136430: expected 15 fields, saw 22\n",
      "Skipping line 1139815: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1179821: expected 15 fields, saw 22\n",
      "Skipping line 1195351: expected 15 fields, saw 22\n",
      "Skipping line 1202007: expected 15 fields, saw 22\n",
      "Skipping line 1224868: expected 15 fields, saw 22\n",
      "Skipping line 1232490: expected 15 fields, saw 22\n",
      "Skipping line 1238697: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1258654: expected 15 fields, saw 22\n",
      "Skipping line 1279948: expected 15 fields, saw 22\n",
      "Skipping line 1294360: expected 15 fields, saw 22\n",
      "Skipping line 1302240: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1413654: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1687095: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1805966: expected 15 fields, saw 22\n",
      "\n",
      "Skipping line 1892134: expected 15 fields, saw 22\n",
      "\n",
      "/var/folders/xx/d1tzxzhj3fzbmswz4z7m_40w0000gn/T/ipykernel_12645/1150709939.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  full_data = pd.read_csv(\"./amazon_reviews_us_Office_Products_v1_00.tsv\", delimiter='\\t', encoding='utf-8', error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "# Reading the data from the tsv (Amazon Kitchen dataset) file as a Pandas frame\n",
    "full_data = pd.read_csv(\"./amazon_reviews_us_Office_Products_v1_00.tsv\", delimiter='\\t', encoding='utf-8', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
      "0                US     43081963  R18RVCKGH1SSI9  B001BM2MAC       307809868   \n",
      "1                US     10951564  R3L4L6LW1PUOFY  B00DZYEXPQ        75004341   \n",
      "2                US     21143145  R2J8AWXWTDX2TF  B00RTMUHDW       529689027   \n",
      "3                US     52782374  R1PR37BR7G3M6A  B00D7H8XB6       868449945   \n",
      "4                US     24045652  R3BDDDZMZBZDPU  B001XCWP34        33521401   \n",
      "...             ...          ...             ...         ...             ...   \n",
      "2640249          US     53005790   RLI7EI10S7SN0  B00000DM9M       223408988   \n",
      "2640250          US     52188548  R1F3SRK9MHE6A3  B00000DM9M       223408988   \n",
      "2640251          US     52090046  R23V0C4NRJL8EM  0807865001       307284585   \n",
      "2640252          US     52503173  R13ZAE1ATEUC1T  1572313188       870359649   \n",
      "2640253          US     52585611   RE8J5O2GY04NN  1572313188       870359649   \n",
      "\n",
      "                                             product_title product_category  \\\n",
      "0           Scotch Cushion Wrap 7961, 12 Inches x 100 Feet  Office Products   \n",
      "1                Dust-Off Compressed Gas Duster, Pack of 4  Office Products   \n",
      "2        Amram Tagger Standard Tag Attaching Tagging Gu...  Office Products   \n",
      "3        AmazonBasics 12-Sheet High-Security Micro-Cut ...  Office Products   \n",
      "4        Derwent Colored Pencils, Inktense Ink Pencils,...  Office Products   \n",
      "...                                                    ...              ...   \n",
      "2640249                 PalmOne III Leather Belt Clip Case  Office Products   \n",
      "2640250                 PalmOne III Leather Belt Clip Case  Office Products   \n",
      "2640251                  Gods and Heroes of Ancient Greece  Office Products   \n",
      "2640252  Microsoft EXCEL 97/ Visual Basic Step-by-Step ...  Office Products   \n",
      "2640253  Microsoft EXCEL 97/ Visual Basic Step-by-Step ...  Office Products   \n",
      "\n",
      "        star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
      "0                 5            0.0          0.0    N                 Y   \n",
      "1                 5            0.0          1.0    N                 Y   \n",
      "2                 5            0.0          0.0    N                 Y   \n",
      "3                 1            2.0          3.0    N                 Y   \n",
      "4                 4            0.0          0.0    N                 Y   \n",
      "...             ...            ...          ...  ...               ...   \n",
      "2640249           4           26.0         26.0    N                 N   \n",
      "2640250           4           18.0         18.0    N                 N   \n",
      "2640251           4            9.0         16.0    N                 N   \n",
      "2640252           5            0.0          0.0    N                 N   \n",
      "2640253           5            0.0          0.0    N                 N   \n",
      "\n",
      "                                           review_headline  \\\n",
      "0                                               Five Stars   \n",
      "1        Phffffffft, Phfffffft. Lots of air, and it's C...   \n",
      "2                            but I am sure I will like it.   \n",
      "3        and the shredder was dirty and the bin was par...   \n",
      "4                                               Four Stars   \n",
      "...                                                    ...   \n",
      "2640249  Great value! A must if you hate to carry thing...   \n",
      "2640250          Attaches the Palm Pilot like an appendage   \n",
      "2640251  Excellent information, pictures and stories, I...   \n",
      "2640252                                         class text   \n",
      "2640253                                 Microsoft's Finest   \n",
      "\n",
      "                                               review_body review_date  \n",
      "0                                           Great product.  2015-08-31  \n",
      "1        What's to say about this commodity item except...  2015-08-31  \n",
      "2          Haven't used yet, but I am sure I will like it.  2015-08-31  \n",
      "3        Although this was labeled as &#34;new&#34; the...  2015-08-31  \n",
      "4                          Gorgeous colors and easy to use  2015-08-31  \n",
      "...                                                    ...         ...  \n",
      "2640249  I can't live anymore whithout my Palm III. But...  1998-12-07  \n",
      "2640250  Although the Palm Pilot is thin and compact it...  1998-11-30  \n",
      "2640251  This book had a lot of great content without b...  1998-10-15  \n",
      "2640252  I am teaching a course in Excel and am using t...  1998-08-22  \n",
      "2640253  A very comprehensive layout of exactly how Vis...  1998-07-15  \n",
      "\n",
      "[2640254 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Printing the data frame that contains the entire dataset from the tsv file\n",
    "print(full_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================Sample Reviews:===========================\n",
      "                                               review_body  star_rating  \\\n",
      "825367   I feel like such a pro with this presenter! Pr...          5.0   \n",
      "345381                                      Great purchase          5.0   \n",
      "2450776  I purchased the Canon MP620 to replace an Epso...          4.0   \n",
      "\n",
      "                     review_headline  \n",
      "825367              Great presenter!  \n",
      "345381                    Five Stars  \n",
      "2450776  Excellent buy for the money  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/d1tzxzhj3fzbmswz4z7m_40w0000gn/T/ipykernel_12645/297036716.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['star_rating'] = pd.to_numeric(data['star_rating'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Keep only the Reviews and Ratings fields from the full data\n",
    "data = full_data[['review_body', 'star_rating', 'review_headline']]\n",
    "\n",
    "# Converting 'star_rating' to numeric values\n",
    "data['star_rating'] = pd.to_numeric(data['star_rating'], errors='coerce')\n",
    "\n",
    "# Displaying three sample reviews along with ratings\n",
    "sample_reviews = data.sample(3)\n",
    "print(\"=========================Sample Reviews:===========================\")\n",
    "print(sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================Ratings Statistics:============================\n",
      "Ratings Count:\n",
      "1.0     306979\n",
      "2.0     138384\n",
      "3.0     193691\n",
      "4.0     418371\n",
      "5.0    1582812\n",
      "Name: star_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reporting statistics of the ratings\n",
    "ratings_statistics = data['star_rating'].value_counts().sort_index()\n",
    "print(\"\\n========================Ratings Statistics:============================\")\n",
    "print(\"Ratings Count:\")\n",
    "print(ratings_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  Form two classes and select 100000 reviews randomly from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/d1tzxzhj3fzbmswz4z7m_40w0000gn/T/ipykernel_12645/18226587.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['sentiment'] = data['star_rating'].apply(lambda x: 1 if x > 3 else 0 if x <= 2 else None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               review_body  star_rating  \\\n",
      "980067   Yes they're thin, but they're sturdy and do th...          5.0   \n",
      "655902          order came in just fine, would order again          5.0   \n",
      "1249308               exactly as it appears great for work          4.0   \n",
      "2190006  I just set this up in my classroom. It is actu...          5.0   \n",
      "935188                                        good product          5.0   \n",
      "...                                                    ...          ...   \n",
      "289745   I have a Brother MFC -J6720DW.  Unfortunately ...          2.0   \n",
      "702019   I was extremely disappointed with this product...          1.0   \n",
      "2530891  I was excited about this all-in-one based on r...          2.0   \n",
      "1200675  Alright, so you think to yourself this is goin...          1.0   \n",
      "2214545  These clips do not work on stainless steel ref...          1.0   \n",
      "\n",
      "                                           review_headline  sentiment  \n",
      "980067                                     Thin but Sturdy        1.0  \n",
      "655902                                  Name Badge magnets        1.0  \n",
      "1249308                                         Four Stars        1.0  \n",
      "2190006                                     Great product!        1.0  \n",
      "935188                                          Five Stars        1.0  \n",
      "...                                                    ...        ...  \n",
      "289745            Doesn't work wiith  Brother MFC -J6720DW        0.0  \n",
      "702019                     Don't buy if you are a teacher!        0.0  \n",
      "2530891                                        Ink Guzzler        0.0  \n",
      "1200675  Failed, the magnet fell off after a few days w...        0.0  \n",
      "2214545                                  Clips don't work!        0.0  \n",
      "\n",
      "[200000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Creating binary labels for sentiment analysis\n",
    "data['sentiment'] = data['star_rating'].apply(lambda x: 1 if x > 3 else 0 if x <= 2 else None)\n",
    "\n",
    "# Discarding neutral reviews (rating 3)\n",
    "data = data.dropna(subset=['sentiment'])\n",
    "\n",
    "# Selecting 100,000 positive and 100,000 negative reviews\n",
    "positive_reviews = data[data['sentiment'] == 1].sample(100000, random_state=42)\n",
    "negative_reviews = data[data['sentiment'] == 0].sample(100000, random_state=42)\n",
    "\n",
    "# Concatenating positive and negative reviews into a single data set for further test and train set split\n",
    "selected_reviews = pd.concat([positive_reviews, negative_reviews])\n",
    "\n",
    "# Printing the reviews that have been selected for further processing randomly\n",
    "print(selected_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Split the dataset into training and testing dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(selected_reviews['review_body'],\n",
    "                                                    selected_reviews['sentiment'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2472632    I'm sorry I bought this printer.  I guess it's...\n",
      "1568399    Its a bit crude i must admit, but i still thou...\n",
      "766793     Prints are blurry no matter how many times the...\n",
      "1501214    Not worth $5,00 folder is made of cheap plasti...\n",
      "59127                      I got two. They both didn't work-\n",
      "                                 ...                        \n",
      "1824293    It has a variety of colors, but there's a thin...\n",
      "968776                      Fell apart in less than 2 weeks.\n",
      "1126758    I bought this product a little over a year ago...\n",
      "1745055    From the beginning, the pages printed terribly...\n",
      "2237191    With the MagicJack Plus I have successfully ma...\n",
      "Name: review_body, Length: 160000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Printing the Features of the training set\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2292297    worked fine for a week. then auto feed malfunc...\n",
      "1067920                                                GREAT\n",
      "2626155    This toy was not created well for babies stand...\n",
      "574517                                They work as expected.\n",
      "704740     very high quality like original ink. Love it a...\n",
      "                                 ...                        \n",
      "1933307    It doesn't pay to buy off name folders. The Pe...\n",
      "928345                                             excellent\n",
      "1898808    when working numbers in a fast paced environme...\n",
      "307872     None of them worked. I'm going back to purchas...\n",
      "1935724    I worked as a quality manager in paper manufac...\n",
      "Name: review_body, Length: 40000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Printing the Features of the testing set\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2472632    0.0\n",
      "1568399    1.0\n",
      "766793     0.0\n",
      "1501214    0.0\n",
      "59127      0.0\n",
      "          ... \n",
      "1824293    0.0\n",
      "968776     0.0\n",
      "1126758    0.0\n",
      "1745055    0.0\n",
      "2237191    0.0\n",
      "Name: sentiment, Length: 160000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Printing the Target(s) of the training set\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2292297    0.0\n",
      "1067920    1.0\n",
      "2626155    0.0\n",
      "574517     1.0\n",
      "704740     1.0\n",
      "          ... \n",
      "1933307    1.0\n",
      "928345     1.0\n",
      "1898808    0.0\n",
      "307872     0.0\n",
      "1935724    1.0\n",
      "Name: sentiment, Length: 40000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Printing the Target(s) of the testing set\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xx/d1tzxzhj3fzbmswz4z7m_40w0000gn/T/ipykernel_12645/2837347252.py:75: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  reviews = reviews.apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
      "/var/folders/xx/d1tzxzhj3fzbmswz4z7m_40w0000gn/T/ipykernel_12645/2837347252.py:75: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  reviews = reviews.apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Printing the Average lenght of Reviews Before and After Cleaning====================\n",
      "\n",
      "Average Length of Reviews (Before Cleaning): 318 characters\n",
      "Average Length of Reviews (After Cleaning): 300 characters\n"
     ]
    }
   ],
   "source": [
    "# Define a contraction map\n",
    "CONTRACTION_MAP = {\n",
    "    \"won't\": \"will not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"that'll\": \"that will\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\"\n",
    "}\n",
    "\n",
    "# Function to expand contractions\n",
    "def expand_contractions(text):\n",
    "    for contraction, expansion in CONTRACTION_MAP.items():\n",
    "        text = re.sub(contraction, expansion, text)\n",
    "    return text\n",
    "\n",
    "# Preprocess the reviews\n",
    "def preprocess_reviews(reviews):\n",
    "    # Convert to lowercase and handle NaN values\n",
    "    reviews = reviews.apply(lambda x: str(x).lower() if pd.notna(x) else '')\n",
    "    \n",
    "    # Remove HTML and URLs\n",
    "    reviews = reviews.apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())\n",
    "    reviews = reviews.apply(lambda x: re.sub(r'http\\S+', '', x))\n",
    "\n",
    "    # Remove non-alphabetical characters\n",
    "    reviews = reviews.apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "\n",
    "    # Remove extra spaces\n",
    "    reviews = reviews.apply(lambda x: re.sub(' +', ' ', x))\n",
    "\n",
    "    # Perform contractions\n",
    "    reviews = reviews.apply(expand_contractions)\n",
    "\n",
    "    # Return the processed text of the review\n",
    "    return reviews\n",
    "\n",
    "# Preprocess the training set\n",
    "X_train_preprocessed = preprocess_reviews(X_train)\n",
    "\n",
    "# Print average length of reviews before and after cleaning\n",
    "avg_length_before = X_train.apply(lambda x: len(str(x))).mean()\n",
    "avg_length_after = X_train_preprocessed.apply(len).mean()\n",
    "print(\"===================Printing the Average lenght of Reviews Before and After Cleaning====================\")\n",
    "print(f\"\\nAverage Length of Reviews (Before Cleaning): {int(avg_length_before)} characters\")\n",
    "print(f\"Average Length of Reviews (After Cleaning): {int(avg_length_after)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "### -- remove the stop words\n",
    "### -- perform lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Printing Sample Reviews Before and After Pre-processing =============\n",
      "\n",
      "Sample Review 591443 Before Pre-processing:\n",
      "printer did not work at all as the carriage was stuck in the far right position\n",
      "\n",
      "Sample Review 591443 After NLTK Pre-processing:\n",
      "printer work carriage stuck far right position\n",
      "\n",
      "Sample Review 1498236 Before Pre-processing:\n",
      "product was as advertised and is a great teaching tool tool set provides large visuals for students and offers a varity\n",
      "\n",
      "Sample Review 1498236 After NLTK Pre-processing:\n",
      "product advertised great teaching tool tool set provides large visuals student offer varity\n",
      "\n",
      "Sample Review 2161966 Before Pre-processing:\n",
      "ive had this for about a year i had my nd staples mailmate die on me in years with pretty light home usei bought this amazon basics but have been disappointed with performance its underpowered jams often gets stuck runningtoo bad ive liked all the other amazon basics products ive purchased\n",
      "\n",
      "Sample Review 2161966 After NLTK Pre-processing:\n",
      "ive year nd staple mailmate die year pretty light home usei bought amazon basic disappointed performance underpowered jam often get stuck runningtoo bad ive liked amazon basic product ive purchased\n",
      "=================Printing the Average lenght of Reviews Before and After Pre-processing==================\n",
      "\n",
      "Average Length of Reviews (Before NLTK Processing): 300 characters\n",
      "Average Length of Reviews (After NLTK Processing): 190 characters\n"
     ]
    }
   ],
   "source": [
    "# Initialize NLTK's stopwords and WordNet lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to remove stop words and perform lemmatization\n",
    "def preprocess_nltk(review):\n",
    "    if pd.notna(review):\n",
    "        words = nltk.word_tokenize(str(review).lower())  # Convert to lowercase\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word.isalpha() and word not in stop_words]\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Preprocess the training set using NLTK\n",
    "X_train_nltk_preprocessed = X_train_preprocessed.apply(preprocess_nltk)\n",
    "\n",
    "# Print three sample reviews before and after NLTK preprocessing\n",
    "sample_reviews_indices = X_train_preprocessed.sample(3).index\n",
    "\n",
    "print(\"============ Printing Sample Reviews Before and After Pre-processing =============\")\n",
    "for index in sample_reviews_indices:\n",
    "    print(f\"\\nSample Review {index} Before Pre-processing:\")\n",
    "    print(X_train_preprocessed.loc[index])\n",
    "\n",
    "    print(f\"\\nSample Review {index} After NLTK Pre-processing:\")\n",
    "    print(X_train_nltk_preprocessed.loc[index])\n",
    "\n",
    "# Print average length of reviews before and after NLTK processing\n",
    "avg_length_before_nltk = X_train_preprocessed.apply(len).mean()\n",
    "avg_length_after_nltk = X_train_nltk_preprocessed.apply(len).mean()\n",
    "print(\"\\n=================Printing the Average lenght of Reviews Before and After Pre-processing==================\")\n",
    "print(f\"\\nAverage Length of Reviews (Before NLTK Processing): {int(avg_length_before_nltk)} characters\")\n",
    "print(f\"Average Length of Reviews (After NLTK Processing): {int(avg_length_after_nltk)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of X_train_tfidf: (160000, 108488)\n",
      "Shape of X_test_tfidf: (40000, 108488)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000000)\n",
    "\n",
    "# Fit and transform the training set\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_nltk_preprocessed)\n",
    "\n",
    "# Transform the test set\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test.apply(preprocess_nltk))\n",
    "\n",
    "# Print the shape of the TF-IDF matrices\n",
    "print(f\"\\nShape of X_train_tfidf: {X_train_tfidf.shape}\")\n",
    "print(f\"Shape of X_test_tfidf: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Training Set Metrics: (Perceptron) ===================\n",
      "Accuracy: 0.91620625\n",
      "Precision: 0.9258094215129661\n",
      "Recall: 0.9049458172409914\n",
      "F1-score: 0.9152587367502892\n",
      "\n",
      "================== Testing Set Metrics: (Perceptron) ====================\n",
      "Accuracy: 0.83635\n",
      "Precision: 0.8197555523850287\n",
      "Recall: 0.8621517531135897\n",
      "F1-score: 0.8404193076548025\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Perceptron model\n",
    "perceptron_model = Perceptron(random_state=42)\n",
    "\n",
    "# Train the Perceptron model on the TF-IDF features\n",
    "perceptron_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_train_pred = perceptron_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred = perceptron_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n================== Training Set Metrics: (Perceptron) ===================\")\n",
    "print(f\"Accuracy: {accuracy_train}\")\n",
    "print(f\"Precision: {precision_train}\")\n",
    "print(f\"Recall: {recall_train}\")\n",
    "print(f\"F1-score: {f1_train}\")\n",
    "\n",
    "print(f\"\\n================== Testing Set Metrics: (Perceptron) ====================\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1-score: {f1_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Training Set Metrics: (SVM) ====================\n",
      "Accuracy: 0.97399375\n",
      "Precision: 0.974595149300428\n",
      "Recall: 0.9733648305773245\n",
      "F1-score: 0.9739796014082657\n",
      "\n",
      "================== Testing Set Metrics: (SVM) ====================\n",
      "Accuracy: 0.903925\n",
      "Precision: 0.8963773807186334\n",
      "Recall: 0.9133696793877857\n",
      "F1-score: 0.90479375696767\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "# Train the SVM model on the TF-IDF features\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_train_pred_svm = svm_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred_svm = svm_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "accuracy_train_svm = accuracy_score(y_train, y_train_pred_svm)\n",
    "precision_train_svm = precision_score(y_train, y_train_pred_svm)\n",
    "recall_train_svm = recall_score(y_train, y_train_pred_svm)\n",
    "f1_train_svm = f1_score(y_train, y_train_pred_svm)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "accuracy_test_svm = accuracy_score(y_test, y_test_pred_svm)\n",
    "precision_test_svm = precision_score(y_test, y_test_pred_svm)\n",
    "recall_test_svm = recall_score(y_test, y_test_pred_svm)\n",
    "f1_test_svm = f1_score(y_test, y_test_pred_svm)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n================== Training Set Metrics: (SVM) ====================\")\n",
    "print(f\"Accuracy: {accuracy_train_svm}\")\n",
    "print(f\"Precision: {precision_train_svm}\")\n",
    "print(f\"Recall: {recall_train_svm}\")\n",
    "print(f\"F1-score: {f1_train_svm}\")\n",
    "\n",
    "print(f\"\\n================== Testing Set Metrics: (SVM) ====================\")\n",
    "print(f\"Accuracy: {accuracy_test_svm}\")\n",
    "print(f\"Precision: {precision_test_svm}\")\n",
    "print(f\"Recall: {recall_test_svm}\")\n",
    "print(f\"F1-score: {f1_test_svm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sakethanne/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Training Set Metrics: (Logistic Regression) ====================\n",
      "Accuracy: 0.9125625\n",
      "Precision: 0.9156665953079548\n",
      "Recall: 0.9088454760208482\n",
      "F1-score: 0.912243284949002\n",
      "\n",
      "================== Testing Set Metrics: (Logistic Regression) ====================\n",
      "Accuracy: 0.8929\n",
      "Precision: 0.887627695800227\n",
      "Recall: 0.899614865202821\n",
      "F1-score: 0.893581081081081\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the Logistic Regression model on the TF-IDF features\n",
    "logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_train_pred_logreg = logreg_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred_logreg = logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "accuracy_train_logreg = accuracy_score(y_train, y_train_pred_logreg)\n",
    "precision_train_logreg = precision_score(y_train, y_train_pred_logreg)\n",
    "recall_train_logreg = recall_score(y_train, y_train_pred_logreg)\n",
    "f1_train_logreg = f1_score(y_train, y_train_pred_logreg)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "accuracy_test_logreg = accuracy_score(y_test, y_test_pred_logreg)\n",
    "precision_test_logreg = precision_score(y_test, y_test_pred_logreg)\n",
    "recall_test_logreg = recall_score(y_test, y_test_pred_logreg)\n",
    "f1_test_logreg = f1_score(y_test, y_test_pred_logreg)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n================== Training Set Metrics: (Logistic Regression) ====================\")\n",
    "print(f\"Accuracy: {accuracy_train_logreg}\")\n",
    "print(f\"Precision: {precision_train_logreg}\")\n",
    "print(f\"Recall: {recall_train_logreg}\")\n",
    "print(f\"F1-score: {f1_train_logreg}\")\n",
    "\n",
    "print(f\"\\n================== Testing Set Metrics: (Logistic Regression) ====================\")\n",
    "print(f\"Accuracy: {accuracy_test_logreg}\")\n",
    "print(f\"Precision: {precision_test_logreg}\")\n",
    "print(f\"Recall: {recall_test_logreg}\")\n",
    "print(f\"F1-score: {f1_test_logreg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================== Training Set Metrics: (Multinomial Naive Bayes) ====================\n",
      "Accuracy: 0.88323125\n",
      "Precision: 0.9019769789454364\n",
      "Recall: 0.8599372554901447\n",
      "F1-score: 0.8804555779505391\n",
      "\n",
      "================== Testing Set Metrics: (Multinomial Naive Bayes) ====================\n",
      "Accuracy: 0.860325\n",
      "Precision: 0.8706390861376968\n",
      "Recall: 0.846296203671285\n",
      "F1-score: 0.8582950769777057\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train the Multinomial Naive Bayes model on the TF-IDF features\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on the training set\n",
    "y_train_pred_nb = nb_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_test_pred_nb = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "accuracy_train_nb = accuracy_score(y_train, y_train_pred_nb)\n",
    "precision_train_nb = precision_score(y_train, y_train_pred_nb)\n",
    "recall_train_nb = recall_score(y_train, y_train_pred_nb)\n",
    "f1_train_nb = f1_score(y_train, y_train_pred_nb)\n",
    "\n",
    "# Calculate metrics for the test set\n",
    "accuracy_test_nb = accuracy_score(y_test, y_test_pred_nb)\n",
    "precision_test_nb = precision_score(y_test, y_test_pred_nb)\n",
    "recall_test_nb = recall_score(y_test, y_test_pred_nb)\n",
    "f1_test_nb = f1_score(y_test, y_test_pred_nb)\n",
    "\n",
    "# Print the results\n",
    "print(f\"\\n================== Training Set Metrics: (Multinomial Naive Bayes) ====================\")\n",
    "print(f\"Accuracy: {accuracy_train_nb}\")\n",
    "print(f\"Precision: {precision_train_nb}\")\n",
    "print(f\"Recall: {recall_train_nb}\")\n",
    "print(f\"F1-score: {f1_train_nb}\")\n",
    "\n",
    "print(f\"\\n================== Testing Set Metrics: (Multinomial Naive Bayes) ====================\")\n",
    "print(f\"Accuracy: {accuracy_test_nb}\")\n",
    "print(f\"Precision: {precision_test_nb}\")\n",
    "print(f\"Recall: {recall_test_nb}\")\n",
    "print(f\"F1-score: {f1_test_nb}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
